{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Tensor will be created on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Create a 3D tensor of zeros directly on the GPU\n",
    "    randn_tensor_gpu1 = torch.randn((3, 2, 4), device='cuda')\n",
    "else:\n",
    "    print(\"CUDA is not available. Tensor will be created on CPU.\")\n",
    "    randn_tensor_gpu2 = torch.randn((800, 800, 800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: Number of epochs with no improvement after which training will be stopped.\n",
    "        :param min_delta: Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Markdown working and maybe add the tensorboard thing\n",
    "# Add the device to the \n",
    "# Deleting plot but just keep the same one everytime. \n",
    "# Getting parameters right and running \n",
    "# Running for 500 epochs (goal)\n",
    "# Get this going tomorrow. \n",
    "\n",
    "# Jobs to ARGON\n",
    "# random spatial cropped\n",
    "# Center spatial cropped\n",
    "# Add device thing for argon\n",
    "\n",
    "\n",
    "# Detach some stuff including the loss: loss.detach() or loss.tocpu()\n",
    "# Also must adjust the number of training and validation images\n",
    "# Should we load and save the optimizer?\n",
    "# Patch size needs to be changed beore sending\n",
    "# Might send the center spatial and random spatial transformation\n",
    "# Might need to change batch size for training data\n",
    "#  num_res_units=2?\n",
    "# to_onehot_y=True ?\n",
    "# Learning rate shceduling (LATER): cosine annealing\n",
    "# Num epochs to be changed for argon\n",
    "#Delete Image folder and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "\n",
    "\n",
    "path = \"z:/W-People/Nate/Deep_Learning_Data/Train/Case_68_Label.nrrd\"\n",
    "\n",
    "data, header = nrrd.read(path)\n",
    "array = np.array(data)\n",
    "\n",
    "np.unique(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Modules\n",
      "Monai imported. Importing Torch\n",
      "Defining the create_dataset function...\n",
      "Setting data paths...\n",
      "Creating datasets...\n",
      "Defining transformations...\n",
      "Initializing data loaders...\n",
      "Initializing U-Net model...\n",
      "Model state loaded successfully.\n",
      "Optimizer state loaded successfully.\n",
      "Setting up loss function and optimizer...\n",
      "Starting the training loop...\n",
      "\n",
      "Reading in the first batch - T ..\n",
      "Training Iteration: 0\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Training Iteration: 1\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Running the validation loop ..\n",
      "Reading in the first batch - V ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "\n",
      "Epoch: 0, Current Learning Rate: 9.999774050118691e-05\n",
      "Plotting losses ..\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Train Loss: 0.5202, Val Loss: 0.7888\n",
      "\n",
      "Reading in the first batch - T ..\n",
      "Training Iteration: 0\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Training Iteration: 1\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Running the validation loop ..\n",
      "Reading in the first batch - V ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "\n",
      "Epoch: 1, Current Learning Rate: 9.999755730091188e-05\n",
      "Plotting losses ..\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Train Loss: 0.5178, Val Loss: 0.7744\n",
      "\n",
      "Reading in the first batch - T ..\n",
      "Training Iteration: 0\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Training Iteration: 1\n",
      "Passing Through the Network\n",
      "Loss Backward\n",
      "Stepping Optimizer\n",
      "Markdown file updated at ./visualization.md\n",
      "\n",
      "Reading in the next batch - T [if any] ..\n",
      "Running the validation loop ..\n",
      "Reading in the first batch - V ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "Markdown file updated at ./visualization.md\n",
      "Reading in the next batch - V [if any] ..\n",
      "\n",
      "Epoch: 2, Current Learning Rate: 9.99972519676224e-05\n",
      "Plotting losses ..\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3] - Train Loss: 0.5165, Val Loss: 0.7620\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing Modules\")\n",
    "import os\n",
    "from monai.transforms import (Compose, LoadImaged, EnsureChannelFirstd, RandSpatialCropd, CenterSpatialCropd, RandRotate90d, ToTensord, ScaleIntensityRanged)\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import Dataset, DataLoader\n",
    "print(\"Monai imported. Importing Torch\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "md_file_path = \"./visualization.md\"\n",
    "\n",
    "\n",
    "\n",
    "# image_folder = \"./PNG/\"\n",
    "\n",
    "# if os.path.exists(md_file_path):\n",
    "#     os.remove(md_file_path)\n",
    "\n",
    "# if os.path.exists(md_file_path):\n",
    "#     PNG\n",
    "\n",
    "print(\"Defining the create_dataset function...\")\n",
    "# Function to create dataset\n",
    "def create_dataset(data_dir):\n",
    "    data_dicts = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\"_Vx3.nrrd\"):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            label_filename = filename.replace(\"_Vx3.nrrd\", \"_Label.nrrd\")\n",
    "            label_path = os.path.join(data_dir, label_filename)\n",
    "            data_dicts.append({'image': image_path, 'label': label_path})\n",
    "    return data_dicts\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# Set data paths\n",
    "train_data_dir = \"z:/W-People/Nate/Deep_Learning_Data/Train\"\n",
    "val_data_dir = \"z:/W-People/Nate/Deep_Learning_Data/Validation\"\n",
    "model_save_path = \"z:/W-People/Nate/Deep_Learning_Data/Nate_Unet(NEWTRY).pth\"\n",
    "optimizer_save_path = \"z:/W-People/Nate/Deep_Learning_Data/Nate_Unet_optimizer(NEWTRY).pth\"\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_files = create_dataset(train_data_dir)\n",
    "val_files = create_dataset(val_data_dir)\n",
    "\n",
    "# Define the size of the cropped region\n",
    "# roi_size = (128, 128, 128)\n",
    "roi_size = (64, 64, 64) #####################################################################\n",
    "print(\"Defining transformations...\")\n",
    "# Transformations\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    CenterSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    RandRotate90d(keys=['image', 'label'], prob=0.5),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Initializing data loaders...\")\n",
    "# Data Loaders\n",
    "train_ds = Dataset(train_files, train_transforms)\n",
    "val_ds = Dataset(val_files, val_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1)\n",
    "\n",
    "\n",
    "print(\"Initializing U-Net model...\")\n",
    "# Model\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "# IMPORTANT FOR NUMBER OF EPOCHS\n",
    "num_epochs = 3 # Example value\n",
    "display_interval = 1 # Example value\n",
    "\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True) ###############1\n",
    "criterion = loss_function\n",
    "optimizer = Adam(net.parameters(), 1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2000, eta_min=1e-6)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "if os.path.exists(model_save_path):\n",
    "    net.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    print(\"Model state loaded successfully.\")\n",
    "if os.path.exists(optimizer_save_path):\n",
    "    optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "    print(\"Optimizer state loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"Setting up loss function and optimizer...\")\n",
    "# Loss function and optimizer\n",
    "\n",
    "# Training step\n",
    "def train_step(batch_data, model, loss_function, optimizer, device):\n",
    "    # print(\"Reading in the images\")\n",
    "    images, labels = batch_data['image'], batch_data['label']\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Passing Through the Network\")\n",
    "    outputs = model(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    print(\"Loss Backward\")\n",
    "    loss.backward()\n",
    "    print(\"Stepping Optimizer\")\n",
    "    optimizer.step()\n",
    "    return loss.item(), outputs\n",
    "\n",
    "# # Visualization and saving function\n",
    "# def visualize_and_save(inputs, outputs, labels, iteration, epoch):\n",
    "\n",
    "#     with open(md_file_path, \"a\") as md_file:\n",
    "#         slice_idx = inputs.shape[2] // 2\n",
    "#         for i in range(inputs.shape[0]):\n",
    "#             fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#             ax[0].imshow(labels[i, 0, :, :, slice_idx], cmap=\"gray\")\n",
    "#             ax[0].set_title(\"Ground Truth\")\n",
    "#             ax[1].imshow(outputs[i, 0, :, :, slice_idx].detach().cpu(), cmap=\"gray\")\n",
    "#             ax[1].set_title(\"Prediction\")\n",
    "#             img_path = f\"./PNG/Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "#             plt.savefig(img_path) #\".\\ABC.png\"\n",
    "#             plt.close()\n",
    "#             md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "#         md_file.close()\n",
    "\n",
    "#     print(f\"Markdown file updated at {md_file_path}\")\n",
    "# clippingmin = -1100\n",
    "# clippingmax = 3000\n",
    "\n",
    "def visualize_and_save_train(inputs, outputs, labels, iteration, epoch, num_train):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Red for arteries (1)\n",
    "        [225, 0, 0]       # Blue for veins (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            # Get the input image and normalize it for visualization\n",
    "            input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "            input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "            # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "            #                              (clippingmax - clippingmin)\n",
    "\n",
    "            # Get the label and prediction volumes\n",
    "            label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "            output_volume = outputs[i].detach().cpu().numpy()\n",
    "            predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "            # Select the middle slice index after argmax reduction\n",
    "            slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "            label_slice = label_volume[slice_idx]\n",
    "            predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "            # Apply the color map to the label and prediction slices\n",
    "            label_rgb_slice = color_map[label_slice]\n",
    "            prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "            # Create the plots\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            ax[0].imshow(input_slice_mid, cmap='gray', vmin = 0, vmax = 1)\n",
    "            ax[0].set_title(\"Input\")\n",
    "            ax[1].imshow(label_rgb_slice)\n",
    "            ax[1].set_title(\"Ground Truth\")\n",
    "            ax[2].imshow(prediction_rgb_slice)\n",
    "            ax[2].set_title(\"Prediction\")\n",
    "            fig.suptitle(f'TRAINING-{num_train}', fontsize=16)\n",
    "            img_path = f\"./PNG/TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "\n",
    "            # Save the image\n",
    "            plt.savefig(img_path)\n",
    "            plt.close()\n",
    "\n",
    "            # Write to the markdown file\n",
    "            md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "def visualize_and_save_valid(inputs, outputs, labels, iteration, epoch, num):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Blue for A (1)\n",
    "        [255, 0, 0]       # Red for V (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            # Get the input image and normalize it for visualization\n",
    "            input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "            input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "            # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "            #                              (clippingmax - clippingmin)\n",
    "\n",
    "            # Get the label and prediction volumes\n",
    "            label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "            output_volume = outputs[i].detach().cpu().numpy()\n",
    "            predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "            # Select the middle slice index after argmax reduction\n",
    "            slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "            label_slice = label_volume[slice_idx]\n",
    "            predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "            # Apply the color map to the label and prediction slices\n",
    "            label_rgb_slice = color_map[label_slice]\n",
    "            prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "            # Create the plots\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            ax[0].imshow(input_slice_mid, cmap='gray', vmin = 0, vmax = 1)\n",
    "            ax[0].set_title(\"Input\")\n",
    "            ax[1].imshow(label_rgb_slice)\n",
    "            ax[1].set_title(\"Ground Truth\")\n",
    "            ax[2].imshow(prediction_rgb_slice)\n",
    "            ax[2].set_title(\"Prediction\")\n",
    "            fig.suptitle(f'VALIDATION-{num}', fontsize=16)\n",
    "            img_path = f\"./PNG/VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "\n",
    "            # Save the image\n",
    "            plt.savefig(img_path)\n",
    "            plt.close()\n",
    "\n",
    "            # Write to the markdown file\n",
    "            md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "\n",
    "# Loss Plotting Function\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    lgtrainloss = np.log(train_losses)\n",
    "    lgvalidloss = np.log(val_losses)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(lgtrainloss, label='Train Loss')\n",
    "    plt.plot(lgvalidloss, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "print(\"Starting the training loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    num_train = 0\n",
    "    # Training Phase\n",
    "    net.train()\n",
    "    print(\"\\nReading in the first batch - T ..\")\n",
    "    for iteration, batch_data in enumerate(train_loader):\n",
    "        print(f\"Training Iteration: {iteration}\")\n",
    "        loss, output = train_step(batch_data, net, criterion, optimizer, device)\n",
    "        epoch_train_loss += loss\n",
    "        if iteration % display_interval == 0:\n",
    "            visualize_and_save_train(batch_data['image'], output, batch_data['label'], iteration, epoch, num_train) \n",
    "        print(\"\\nReading in the next batch - T [if any] ..\")\n",
    "        num_train = num_train + 1\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    \n",
    "    print(\"Running the validation loop ..\")\n",
    "    # Validation Phase\n",
    "    net.eval()\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        print(\"Reading in the first batch - V ..\")\n",
    "        for batch_data in val_loader:\n",
    "            images, labels = batch_data['image'], batch_data['label']\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "            if iteration % display_interval == 0:\n",
    "                visualize_and_save_valid(batch_data['image'], outputs, batch_data['label'], iteration, epoch, num)\n",
    "            print(\"Reading in the next batch - V [if any] ..\")\n",
    "            num = num + 1\n",
    "        print()    \n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "        print(f\"Epoch: {epoch}, Current Learning Rate: {current_lr}\")\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "\n",
    "    # Plot Losses\n",
    "    print(\"Plotting losses ..\")\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "plt.show()  # Display final plots\n",
    "\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importing Modules\")\n",
    "\n",
    "import os\n",
    "from monai.transforms import (Spacingd, Compose, LoadImaged, EnsureChannelFirstd, RandSpatialCropd, CenterSpatialCropd, RandRotate90d, ToTensord, ScaleIntensityRanged)\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import Dataset, DataLoader\n",
    "print(\"Monai imported. Importing Torch\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "starttime = time.time()\n",
    "expdesc = \"2 train 5 valid, roi_size = (128, 128, 128), RandSpatialCropd train,\\\n",
    "      RandSpatialCropd valid, train batch_size=4, num_res_units=2,\\\n",
    "         Cosine Annealing lr = 1e-3, eta_min=0, Tmax = 2000, num_epochs = 1400, using old data\" # REMEBER TO CHANGE THIS EACH JOB\n",
    "with open('expdesc.txt', 'w') as file:\n",
    "    file.write(expdesc)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "md_file_path = \"./visualization.md\"\n",
    "\n",
    "\n",
    "print(\"\\nDefining the create_dataset function...\")\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "# Function to create dataset\n",
    "def create_dataset(data_dir):\n",
    "    data_dicts = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\"_Vx3.nrrd\"):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            label_filename = filename.replace(\"_Vx3.nrrd\", \"_Label.nrrd\")\n",
    "            label_path = os.path.join(data_dir, label_filename)\n",
    "            data_dicts.append({'image': image_path, 'label': label_path})\n",
    "    return data_dicts\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# Set data paths\n",
    "train_data_dir = \"../../TrainData/\"\n",
    "val_data_dir = \"../../ValidationData/\"\n",
    "model_save_path = \"./model/Nate_Unet.pth\"\n",
    "optimizer_save_path = \"./model/Nate_Unet_optimizer.pth\"\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_files = create_dataset(train_data_dir)\n",
    "val_files = create_dataset(val_data_dir)\n",
    "\n",
    "downsampling_transform = Spacingd(\n",
    "    keys=['image', 'label'], \n",
    "    pixdim=(0.8, 0.8, 0.8), \n",
    "    mode=('bilinear', 'nearest') ###############################################################\n",
    ")\n",
    "\n",
    "# Define the size of the cropped region\n",
    "roi_size = (128, 128, 128)\n",
    "# roi_size = (64, 64, 64)\n",
    "print(\"Defining transformations...\")\n",
    "# Transformations\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform, #####################################################################\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    RandRotate90d(keys=['image', 'label'], prob=0.5),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform,\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Initializing data loaders...\")\n",
    "# Data Loaders\n",
    "train_ds = Dataset(train_files, train_transforms)\n",
    "val_ds = Dataset(val_files, val_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4)\n",
    "\n",
    "\n",
    "print(\"Initializing U-Net model...\")\n",
    "# Model\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True) #########################################\n",
    "criterion = loss_function\n",
    "optimizer = Adam(net.parameters(), 1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2000, eta_min=0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\", exist_ok=True)\n",
    "if os.path.exists(model_save_path):\n",
    "    net.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    print(\"Model state loaded successfully.\")\n",
    "if os.path.exists(optimizer_save_path):\n",
    "    optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "    print(\"Optimizer state loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"Setting up loss function and optimizer...\")\n",
    "# Loss function and optimizer\n",
    "\n",
    "# Training step\n",
    "def train_step(batch_data, model, loss_function, optimizer, device):\n",
    "    # print(\"Reading in the images\")\n",
    "    images, labels = batch_data['image'], batch_data['label']\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Passing Through the Network\")\n",
    "    outputs = model(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    print(\"Loss Backward\")\n",
    "    loss.backward()\n",
    "    print(\"Stepping Optimizer\")\n",
    "    optimizer.step()\n",
    "    return loss.item(), outputs\n",
    "\n",
    "# Visualization and saving function\n",
    "# def visualize_and_save(inputs, outputs, labels, iteration, epoch):\n",
    "\n",
    "#     if not os.path.exists(\"./PNG\"):\n",
    "#         os.makedirs(\"./PNG\", exist_ok=True)\n",
    "\n",
    "#     with open(md_file_path, \"a\") as md_file:\n",
    "#         slice_idx = inputs.shape[2] // 2\n",
    "#         for i in range(inputs.shape[0]):\n",
    "#             fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#             ax[0].imshow(labels[i, 0, :, :, slice_idx], cmap=\"gray\")\n",
    "#             ax[0].set_title(\"Ground Truth\")\n",
    "#             ax[1].imshow(outputs[i, 0, :, :, slice_idx].detach().cpu(), cmap=\"gray\")\n",
    "#             ax[1].set_title(\"Prediction\")\n",
    "#             img_path = f\"./PNG/Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "#             plt.savefig(img_path) #\".\\ABC.png\"\n",
    "#             plt.close()\n",
    "#             md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "#         md_file.close()\n",
    "\n",
    "#     print(f\"Markdown file updated at {md_file_path}\")\n",
    "# clippingmin = -1100\n",
    "# clippingmax = 3000 #############################################################################\n",
    "\n",
    "def visualize_and_save_train(inputs, outputs, labels, iteration, epoch, num_train):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Red for arteries (1)\n",
    "        [225, 0, 0]       # Blue for veins (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'TRAINING-{num_train}', fontsize=16)\n",
    "                img_path = f\"./PNG/TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "def visualize_and_save_valid(inputs, outputs, labels, iteration, epoch, num):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Blue for A (1)\n",
    "        [255, 0, 0]       # Red for V (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'VALIDATION-{num}', fontsize=16)\n",
    "                img_path = f\"./PNG/VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "\n",
    "# Loss Plotting Function\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    plt.savefig(\"./PNG/lossfunction.png\")\n",
    "\n",
    "# Main training loop\n",
    "num_epochs = 1400 # Example value\n",
    "display_interval = 1 # Example value\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "print(\"Starting the training loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    num_train = 0\n",
    "\n",
    "    # Training Phase\n",
    "    net.train()\n",
    "    print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "    print(\"\\nReading in the first batch - T ..\")\n",
    "    for iteration, batch_data in enumerate(train_loader):\n",
    "        print(f\"Training Iteration: {iteration}\")\n",
    "        loss, output = train_step(batch_data, net, criterion, optimizer, device)\n",
    "        epoch_train_loss += loss\n",
    "        if iteration % display_interval == 0:\n",
    "            visualize_and_save_train(batch_data['image'], output, batch_data['label'], iteration, epoch, num_train) \n",
    "        print(\"\\nReading in the next batch - T [if any] ..\")\n",
    "        num_train = num_train + 1\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(\"Running the validation loop ..\")\n",
    "    \n",
    "    # Validation Phase\n",
    "    net.eval()\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        print(\"Reading in the first batch - V ..\")\n",
    "        for batch_data in val_loader:\n",
    "            images, labels = batch_data['image'], batch_data['label']\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "            if iteration % display_interval == 0:\n",
    "                visualize_and_save_valid(batch_data['image'], output, batch_data['label'], iteration, epoch, num) \n",
    "            print(\"Reading in the next batch - V [if any] ..\")\n",
    "            num = num + 1\n",
    "        print()    \n",
    "    \n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "        print(f\"Epoch: {epoch}, Current Learning Rate: {current_lr}\")\n",
    "    # Plot Losses\n",
    "    print(\"Plotting losses ..\")\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# plt.ioff()  # Turn off interactive mode\n",
    "# plt.show()  # Display final plots\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The 'colormap' trait of an IsoSurfaceFactory instance must be 'Accent' or 'Blues' or 'BrBG' or 'BuGn' or 'BuPu' or 'CMRmap' or 'Dark2' or 'GnBu' or 'Greens' or 'Greys' or 'OrRd' or 'Oranges' or 'PRGn' or 'Paired' or 'Pastel1' or 'Pastel2' or 'PiYG' or 'PuBu' or 'PuBuGn' or 'PuOr' or 'PuRd' or 'Purples' or 'RdBu' or 'RdGy' or 'RdPu' or 'RdYlBu' or 'RdYlGn' or 'Reds' or 'Set1' or 'Set2' or 'Set3' or 'Spectral' or 'Vega10' or 'Vega20' or 'Vega20b' or 'Vega20c' or 'Wistia' or 'YlGn' or 'YlGnBu' or 'YlOrBr' or 'YlOrRd' or 'afmhot' or 'autumn' or 'binary' or 'black-white' or 'blue-red' or 'bone' or 'brg' or 'bwr' or 'cool' or 'coolwarm' or 'copper' or 'cubehelix' or 'file' or 'flag' or 'gist_earth' or 'gist_gray' or 'gist_heat' or 'gist_ncar' or 'gist_rainbow' or 'gist_stern' or 'gist_yarg' or 'gnuplot' or 'gnuplot2' or 'gray' or 'hot' or 'hsv' or 'inferno' or 'jet' or 'magma' or 'nipy_spectral' or 'ocean' or 'pink' or 'plasma' or 'prism' or 'rainbow' or 'seismic' or 'spectral' or 'spring' or 'summer' or 'terrain' or 'viridis' or 'winter',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems to be fixed\n",
    "# input volume should be ct image,,, when showing that in mayavi WHAT ARE YOU ACTUALLY SHOWING?\n",
    "# do use contour 3d\n",
    "# Add early stopping make epochs 200 \n",
    "# first experiment add 5 images in validation train with two images\n",
    "# try to get the best thing we can get just from two images first\n",
    "# use the exact same 5 for validation\n",
    "# ask chat gpt for creating a report (capabilities in monai)\n",
    "# Change learning rate maybe add adaptive learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor=(0, 0, 0))\n",
    "\n",
    "            # Visualize original grayscale image volume\n",
    "            # Adjust the visualization to correctly display the grayscale volume\n",
    "            # The 'volume' function is used for volume rendering of scalar data\n",
    "            mlab.pipeline.volume(mlab.pipeline.scalar_field(input_volume), figure=fig)\n",
    "\n",
    "            # Visualize true label volume\n",
    "            # Assuming target_volume contains discrete labels for segmentation\n",
    "            mlab.contour3d(target_volume, contours=2, color=(0, 1, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            # Assuming predicted_volume contains discrete labels for segmentation\n",
    "            mlab.contour3d(predicted_volume, contours=2, color=(1, 0, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Call the function with appropriate parameters\n",
    "visualize_predictions_3d(val_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor = (0,0,0))\n",
    "\n",
    "            # Visualize original image volume\n",
    "            mlab.contour3d(input_volume, contours=[input_volume.max()/2], color=(0, 0, 1), transparent=True, figure=fig)\n",
    "\n",
    "            # Visualize true label volume\n",
    "            mlab.contour3d(target_volume, contours=[target_volume.max()/2], color=(0, 1, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            mlab.contour3d(predicted_volume, contours=[predicted_volume.max()/2], color=(1, 0, 0), transparent=True, figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Call the function with appropriate parameters\n",
    "visualize_predictions_3d(val_loader, model, device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions_3d(loader, model, device, num_volumes=1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        inputs, targets = batch['image'], batch['label']\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert model output to binary predictions\n",
    "        predicted_labels = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        for i in range(min(num_volumes, len(inputs))):\n",
    "            # Reconstruct 3D volumes\n",
    "            input_volume = inputs[i].cpu().squeeze().numpy()\n",
    "            target_volume = targets[i].cpu().squeeze().numpy()\n",
    "            predicted_volume = predicted_labels[i].cpu().squeeze().numpy()\n",
    "\n",
    "            # Set up a figure\n",
    "            fig = mlab.figure(size=(800, 800), bgcolor=(0, 0, 0))\n",
    "\n",
    "            # Visualize true label volume\n",
    "            target_src = mlab.pipeline.scalar_field(target_volume)\n",
    "            mlab.pipeline.iso_surface(target_src, contours=[target_volume.max() * 0.5], \n",
    "                                      colormap='winter', opacity=.5, figure=fig)\n",
    "\n",
    "            # Visualize predicted label volume\n",
    "            predicted_src = mlab.pipeline.scalar_field(predicted_volume)\n",
    "            mlab.pipeline.iso_surface(predicted_src, contours=[predicted_volume.max() * 0.5], \n",
    "                                      colormap='rainbow', opacity=1, figure=fig)\n",
    "\n",
    "            # Add legends and annotations\n",
    "            mlab.text(0.01, 0.01, \"Target Volume\", color=(0, 0, 1), width=0.15, figure=fig)\n",
    "            mlab.text(0.01, 0.95, \"Predicted Volume\", color=(1, 0, 0), width=0.15, figure=fig)\n",
    "\n",
    "            # Display the visualization\n",
    "            mlab.show()\n",
    "\n",
    "# Assuming val_loader, model, and device have been defined elsewhere in your script:\n",
    "visualize_predictions_3d(val_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AHNet', 'AHnet', 'Ahnet', 'AttentionUnet', 'AutoEncoder', 'BasicUNet', 'BasicUNetPlusPlus', 'BasicUnet', 'BasicUnetPlusPlus', 'Basicunet', 'BasicunetPlusPlus', 'BertAttention', 'BertMixedLayer', 'BertOutput', 'BertPreTrainedModel', 'BlockArgs', 'Classifier', 'Critic', 'DAF3D', 'DenseNet', 'DenseNet121', 'DenseNet169', 'DenseNet201', 'DenseNet264', 'Densenet', 'Densenet121', 'Densenet169', 'Densenet201', 'Densenet264', 'DiNTS', 'Discriminator', 'DynUNet', 'DynUnet', 'Dynunet', 'EfficientNet', 'EfficientNetBN', 'EfficientNetBNFeatures', 'EfficientNetEncoder', 'FLEXUNET_BACKBONE', 'FlexUNet', 'FlexUNetEncoderRegister', 'FlexibleUNet', 'FullyConnectedNet', 'Generator', 'GlobalNet', 'HighResBlock', 'HighResNet', 'HoVerNet', 'HoVernet', 'HoverNet', 'Hovernet', 'LocalNet', 'MILModel', 'MultiModal', 'NetAdapter', 'PatchMerging', 'PatchMergingV2', 'Pooler', 'Quicknat', 'RegUNet', 'Regressor', 'ResNet', 'ResNetBlock', 'ResNetBottleneck', 'SENet', 'SENet154', 'SEResNeXt101', 'SEResNeXt50', 'SEResNet101', 'SEResNet152', 'SEResNet50', 'SEResNext101', 'SEResNext50', 'SEnet', 'SEnet154', 'SEresnet101', 'SEresnet152', 'SEresnet50', 'SEresnext101', 'SEresnext50', 'SegResNet', 'SegResNetDS', 'SegResNetVAE', 'Senet', 'Senet154', 'Seresnet101', 'Seresnet152', 'Seresnet50', 'Seresnext101', 'Seresnext50', 'SwinUNETR', 'TopologyConstruction', 'TopologyInstance', 'TopologySearch', 'TorchVisionFCModel', 'Transchex', 'UNETR', 'UNet', 'Unet', 'VNet', 'VarAutoEncoder', 'VarFullyConnectedNet', 'ViT', 'ViTAutoEnc', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'ahnet', 'annotations', 'attentionunet', 'autoencoder', 'basic_unet', 'basic_unetplusplus', 'basicunet', 'basicunetplusplus', 'classifier', 'daf3d', 'densenet', 'densenet121', 'densenet169', 'densenet201', 'densenet264', 'dints', 'drop_connect', 'dynunet', 'efficientnet', 'flexible_unet', 'fullyconnectednet', 'generator', 'get_efficientnet_image_size', 'highresnet', 'hovernet', 'milmodel', 'netadapter', 'quicknat', 'regressor', 'regunet', 'resnet', 'resnet10', 'resnet101', 'resnet152', 'resnet18', 'resnet200', 'resnet34', 'resnet50', 'segresnet', 'segresnet_ds', 'senet', 'senet154', 'seresnet101', 'seresnet152', 'seresnet50', 'seresnext101', 'seresnext50', 'swin_unetr', 'torchvision_fc', 'transchex', 'unet', 'unetr', 'varautoencoder', 'vit', 'vitautoenc', 'vnet']\n"
     ]
    }
   ],
   "source": [
    "import monai.networks.nets as nets\n",
    "\n",
    "# List all classes and functions in monai.networks.nets\n",
    "print(dir(nets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def list_installed_packages(file_name):\n",
    "    try:\n",
    "        # Running 'pip list' command and capturing the output\n",
    "        installed_packages = subprocess.check_output([sys.executable, '-m', 'pip', 'list'], universal_newlines=True)\n",
    "\n",
    "        # Writing the output to a file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(installed_packages)\n",
    "\n",
    "        print(f\"List of installed packages written to {file_name}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"An error occurred while retrieving the list of installed packages.\")\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the name of the file where you want to save the list\n",
    "    output_file = \"installed_packages_Nate.txt\"\n",
    "    list_installed_packages(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0.00 Minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOB 7\n",
    "\n",
    "\n",
    "\n",
    "print(\"Importing Modules\")\n",
    "\n",
    "import os\n",
    "from monai.transforms import (Spacingd, Compose, LoadImaged, EnsureChannelFirstd, RandSpatialCropd, CenterSpatialCropd, RandRotate90d, ToTensord, ScaleIntensityRanged)\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import Dataset, DataLoader\n",
    "print(\"Monai imported. Importing Torch\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "starttime = time.time()\n",
    "expdesc = \"2 train 5 valid, roi_size = (128, 128, 128), RandSpatialCropd train,\\\n",
    "      RandSpatialCropd valid, train batch_size=4, num_res_units=2,\\\n",
    "         Cosine Annealing lr = 1e-3, eta_min=0, Tmax = 4000, num_epochs = 2000, using old data\" # REMEBER TO CHANGE THIS EACH JOB\n",
    "with open('expdesc.txt', 'w') as file:\n",
    "    file.write(expdesc)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "md_file_path = \"./visualization.md\"\n",
    "\n",
    "\n",
    "print(\"\\nDefining the create_dataset function...\")\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "# Function to create dataset\n",
    "\n",
    "\n",
    "# def create_dataset(data_dir):\n",
    "#     data_dicts = []\n",
    "#     for filename in os.listdir(data_dir):\n",
    "#         if filename.endswith(\"_Vx3.nrrd\"):\n",
    "#             image_path = os.path.join(data_dir, filename)\n",
    "#             label_filename = filename.replace(\"_Vx3.nrrd\", \"_Label.nrrd\")\n",
    "#             label_path = os.path.join(data_dir, label_filename)\n",
    "#             data_dicts.append({'image': image_path, 'label': label_path, 'filename': filename})\n",
    "#     return data_dicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(data_dir, label_dir):\n",
    "    data_dicts = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".nrrd\"):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            label_path = os.path.join(label_dir, filename)\n",
    "            # Include the filename in the dictionary\n",
    "            data_dicts.append({'image': image_path, 'label': label_path, 'filename': filename})\n",
    "    return data_dicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# Set data paths\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# # Set data paths\n",
    "train_data_dir = \"../../TrainDataOld/\"\n",
    "train_label_dir = \"../../TrainDataOld/labels/\"\n",
    "val_data_dir = \"../../ValidationDataOld/\"\n",
    "val_label_dir = \"../../ValidationDataOld/labels/\"\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_files = create_dataset(train_data_dir, train_label_dir)\n",
    "val_files = create_dataset(val_data_dir, val_label_dir)\n",
    "\n",
    "# train_data_dir = \"../../TrainData/\"\n",
    "# val_data_dir = \"../../ValidationData/\"\n",
    "model_save_path = \"./model/Nate_Unet.pth\"\n",
    "optimizer_save_path = \"./model/Nate_Unet_optimizer.pth\"\n",
    "\n",
    "# print(\"Creating datasets...\")\n",
    "# train_files = create_dataset(train_data_dir)\n",
    "# val_files = create_dataset(val_data_dir)\n",
    "\n",
    "downsampling_transform = Spacingd(\n",
    "    keys=['image', 'label'], \n",
    "    pixdim=(0.8, 0.8, 0.8), \n",
    "    mode=('bilinear', 'nearest') ###############################################################\n",
    ")\n",
    "\n",
    "# Define the size of the cropped region\n",
    "roi_size = (128, 128, 128)\n",
    "# roi_size = (64, 64, 64)\n",
    "print(\"Defining transformations...\")\n",
    "# Transformations\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform, #####################################################################\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    RandRotate90d(keys=['image', 'label'], prob=0.5),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform,\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Initializing data loaders...\")\n",
    "# Data Loaders\n",
    "train_ds = Dataset(train_files, train_transforms)\n",
    "val_ds = Dataset(val_files, val_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=4)\n",
    "\n",
    "\n",
    "print(\"Initializing U-Net model...\")\n",
    "# Model\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True) #########################################\n",
    "criterion = loss_function\n",
    "optimizer = Adam(net.parameters(), 1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2000, eta_min=1e-6)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\", exist_ok=True)\n",
    "if os.path.exists(model_save_path):\n",
    "    net.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    print(\"Model state loaded successfully.\")\n",
    "if os.path.exists(optimizer_save_path):\n",
    "    optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "    print(\"Optimizer state loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"Setting up loss function and optimizer...\")\n",
    "# Loss function and optimizer\n",
    "\n",
    "# Training step\n",
    "\n",
    "\n",
    "# Visualization and saving function\n",
    "# def visualize_and_save(inputs, outputs, labels, iteration, epoch):\n",
    "\n",
    "#     if not os.path.exists(\"./PNG\"):\n",
    "#         os.makedirs(\"./PNG\", exist_ok=True)\n",
    "\n",
    "#     with open(md_file_path, \"a\") as md_file:\n",
    "#         slice_idx = inputs.shape[2] // 2\n",
    "#         for i in range(inputs.shape[0]):\n",
    "#             fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#             ax[0].imshow(labels[i, 0, :, :, slice_idx], cmap=\"gray\")\n",
    "#             ax[0].set_title(\"Ground Truth\")\n",
    "#             ax[1].imshow(outputs[i, 0, :, :, slice_idx].detach().cpu(), cmap=\"gray\")\n",
    "#             ax[1].set_title(\"Prediction\")\n",
    "#             img_path = f\"./PNG/Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "#             plt.savefig(img_path) #\".\\ABC.png\"\n",
    "#             plt.close()\n",
    "#             md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "#         md_file.close()\n",
    "\n",
    "#     print(f\"Markdown file updated at {md_file_path}\")\n",
    "# clippingmin = -1100\n",
    "# clippingmax = 3000 #############################################################################\n",
    "\n",
    "def visualize_and_save_train(inputs, outputs, labels, iteration, epoch, num_train):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Red for arteries (1)\n",
    "        [225, 0, 0]       # Blue for veins (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'TRAINING-{num_train}', fontsize=16)\n",
    "                img_path = f\"./PNG/TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "                print(f\"TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\")\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "def visualize_and_save_valid(inputs, outputs, labels, iteration, epoch, num):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Blue for A (1)\n",
    "        [255, 0, 0]       # Red for V (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'VALIDATION-{num}', fontsize=16)\n",
    "                img_path = f\"./PNG/VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "                print(f\"VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\")\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "\n",
    "# Loss Plotting Function\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    plt.savefig(\"./PNG/lossfunction.png\")\n",
    "\n",
    "# Main training loop\n",
    "num_epochs = 1000 # Example value\n",
    "display_interval = 1 # Example value\n",
    "\n",
    "\n",
    "def train_step(batch_data, model, loss_function, optimizer, device):\n",
    "    # print(\"Reading in the images\")\n",
    "    print(f\"Processing filenames: {batch_data['filename']}\")\n",
    "    images, labels = batch_data['image'], batch_data['label']\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Passing Through the Network\")\n",
    "    outputs = model(images)\n",
    "\n",
    "    print(f\"Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "    print(\"Label tensor values (sample):\", labels[0, :, 0, 0, 0])\n",
    "    if torch.any(labels == 3):\n",
    "        print(f\"Filename with label 3: {batch_data['filename']}\")\n",
    "\n",
    "    loss = loss_function(outputs, labels)\n",
    "    print(\"Loss Backward\")\n",
    "    loss.backward()\n",
    "    print(\"Stepping Optimizer\")\n",
    "    optimizer.step()\n",
    "    return loss.item(), outputs\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "print(\"Starting the training loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    \n",
    "\n",
    "    # Training Phase\n",
    "    net.train()\n",
    "    num_train = 0\n",
    "    print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "    print(\"\\nReading in the first batch - T ..\")\n",
    "    for iteration, batch_data in enumerate(train_loader):\n",
    "        print(f\"Training Iteration: {iteration}\")\n",
    "        loss, output = train_step(batch_data, net, criterion, optimizer, device)\n",
    "        epoch_train_loss += loss\n",
    "        if iteration % display_interval == 0:\n",
    "            visualize_and_save_train(batch_data['image'], output, batch_data['label'], iteration, epoch, num_train) \n",
    "        print(\"\\nReading in the next batch - T [if any] ..\")\n",
    "        num_train = num_train + 1\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(\"Running the validation loop ..\")\n",
    "    \n",
    "    # Validation Phase\n",
    "    net.eval()\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        print(\"Reading in the first batch - V ..\")\n",
    "        for batch_data in val_loader:\n",
    "            images, labels = batch_data['image'], batch_data['label']\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            print(f\"Validation - Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "            if iteration % display_interval == 0:\n",
    "                visualize_and_save_valid(batch_data['image'], outputs, batch_data['label'], iteration, epoch, num) \n",
    "            print(\"Reading in the next batch - V [if any] ..\")\n",
    "            num = num + 1\n",
    "        print()    \n",
    "    \n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "        print(f\"Epoch: {epoch}, Current Learning Rate: {current_lr}\")\n",
    "    # Plot Losses\n",
    "    print(\"Plotting losses ..\")\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# plt.ioff()  # Turn off interactive mode\n",
    "# plt.show()  # Display final plots\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilize multiple GPUs\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    if num_gpus > 1:\n",
    "        net = torch.nn.DataParallel(net)  # Wrap the model with DataParallel\n",
    "    net.to(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "#                    Job7                         #\n",
    "#         See Nate One Note for More Info         #\n",
    "#             Utilize Multiple GPUs               #\n",
    "#           Works on HPC currently (.py)          #\n",
    "###################################################     \n",
    "\n",
    "\n",
    "print(\"Importing Modules\")\n",
    "\n",
    "import os\n",
    "from monai.transforms import (Spacingd, Compose, LoadImaged, EnsureChannelFirstd, RandSpatialCropd, CenterSpatialCropd, RandRotate90d, ToTensord, ScaleIntensityRanged, SpatialPadd)\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "from monai.data import Dataset, DataLoader, pad_list_data_collate\n",
    "print(\"Monai imported. Importing Torch\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "starttime = time.time()\n",
    "expdesc = \"2 train 5 valid, roi_size = (128, 128, 128), RandSpatialCropd train,\\\n",
    "      RandSpatialCropd valid, train batch_size=4, num_res_units=2,\\\n",
    "         Cosine Annealing lr = 1e-3, eta_min=0, Tmax = 4000, num_epochs = 2000, using old data\" # REMEBER TO CHANGE THIS EACH JOB\n",
    "with open('expdesc.txt', 'w') as file:\n",
    "    file.write(expdesc)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "md_file_path = \"./visualization.md\"\n",
    "\n",
    "\n",
    "print(\"\\nDefining the create_dataset function...\")\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "# Function to create dataset\n",
    "\n",
    "\n",
    "# def create_dataset(data_dir):\n",
    "#     data_dicts = []\n",
    "#     for filename in os.listdir(data_dir):\n",
    "#         if filename.endswith(\"_Vx3.nrrd\"):\n",
    "#             image_path = os.path.join(data_dir, filename)\n",
    "#             label_filename = filename.replace(\"_Vx3.nrrd\", \"_Label.nrrd\")\n",
    "#             label_path = os.path.join(data_dir, label_filename)\n",
    "#             data_dicts.append({'image': image_path, 'label': label_path, 'filename': filename})\n",
    "#     return data_dicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(data_dir, label_dir):\n",
    "    data_dicts = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".nrrd\"):\n",
    "            image_path = os.path.join(data_dir, filename)\n",
    "            label_path = os.path.join(label_dir, filename)\n",
    "            # Include the filename in the dictionary\n",
    "            data_dicts.append({'image': image_path, 'label': label_path, 'filename': filename})\n",
    "    return data_dicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# Set data paths\n",
    "\n",
    "print(\"Setting data paths...\")\n",
    "# # Set data paths\n",
    "train_data_dir = \"../../TrainDataOld/\"\n",
    "train_label_dir = \"../../TrainDataOld/labels/\"\n",
    "val_data_dir = \"../../ValidationDataOld/\"\n",
    "val_label_dir = \"../../ValidationDataOld/labels/\"\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "train_files = create_dataset(train_data_dir, train_label_dir)\n",
    "val_files = create_dataset(val_data_dir, val_label_dir)\n",
    "\n",
    "# train_data_dir = \"../../TrainData/\"\n",
    "# val_data_dir = \"../../ValidationData/\"\n",
    "model_save_path = \"./model/Nate_Unet.pth\"\n",
    "optimizer_save_path = \"./model/Nate_Unet_optimizer.pth\"\n",
    "\n",
    "# print(\"Creating datasets...\")\n",
    "# train_files = create_dataset(train_data_dir)\n",
    "# val_files = create_dataset(val_data_dir)\n",
    "\n",
    "downsampling_transform = Spacingd(\n",
    "    keys=['image', 'label'], \n",
    "    pixdim=(0.8, 0.8, 0.8), \n",
    "    mode=('bilinear', 'nearest') ###############################################################\n",
    ")\n",
    "\n",
    "# Define the size of the cropped region\n",
    "roi_size = (128, 128, 128)\n",
    "# roi_size = (64, 64, 64)\n",
    "print(\"Defining transformations...\")\n",
    "# Transformations\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform, #####################################################################\n",
    "    SpatialPadd(keys=['image', 'label'], spatial_size=roi_size, method='symmetric'),  # Add padding here\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    RandRotate90d(keys=['image', 'label'], prob=0.5),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=['image', 'label']),\n",
    "    EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    downsampling_transform,\n",
    "    SpatialPadd(keys=['image', 'label'], spatial_size=roi_size, method='symmetric'),  # Add padding here\n",
    "    RandSpatialCropd(keys=['image', 'label'], roi_size=roi_size),\n",
    "    ScaleIntensityRanged(keys=['image'], a_min=-1100, a_max=3000, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ToTensord(keys=['image', 'label']),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Initializing data loaders...\")\n",
    "# Data Loaders\n",
    "train_ds = Dataset(train_files, train_transforms)\n",
    "val_ds = Dataset(val_files, val_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=False, collate_fn=pad_list_data_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, collate_fn=pad_list_data_collate)\n",
    "\n",
    "\n",
    "print(\"Initializing U-Net model...\")\n",
    "# Model\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    if num_gpus > 1:\n",
    "        net = torch.nn.DataParallel(net)  # Wrap the model with DataParallel\n",
    "    net.to(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    net.to(device)\n",
    "\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True) #########################################\n",
    "criterion = loss_function\n",
    "optimizer = Adam(net.parameters(), 1e-3)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2000, eta_min=1e-6)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\", exist_ok=True)\n",
    "if os.path.exists(model_save_path):\n",
    "    net.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    print(\"Model state loaded successfully.\")\n",
    "if os.path.exists(optimizer_save_path):\n",
    "    optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "    print(\"Optimizer state loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"Setting up loss function and optimizer...\")\n",
    "\n",
    "\n",
    "def visualize_and_save_train(inputs, outputs, labels, iteration, epoch, num_train):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Red for arteries (1)\n",
    "        [225, 0, 0]       # Blue for veins (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'TRAINING-{num_train}', fontsize=16)\n",
    "                img_path = f\"./PNG/TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "                print(f\"TRAINING-{num_train}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\")\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "def visualize_and_save_valid(inputs, outputs, labels, iteration, epoch, num):\n",
    "    color_map = np.array([\n",
    "        [255, 255, 255],  # White for background (0)\n",
    "        [0, 0, 255],      # Blue for A (1)\n",
    "        [255, 0, 0]       # Red for V (2)\n",
    "    ], dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    with open(md_file_path, \"a\") as md_file:\n",
    "        for i in range(outputs.shape[0]):  # Iterate over the batch dimension\n",
    "            if i < inputs.shape[0]:\n",
    "                # Get the input image and normalize it for visualization\n",
    "                input_slice = inputs[i, 0, :, :, :].detach().cpu().numpy()\n",
    "                input_slice_mid = input_slice[input_slice.shape[0] // 2]  # Middle slice of the input volume\n",
    "                # input_slice_mid_normalized = (input_slice_mid - clippingmin) / \\\n",
    "                #                             (clippingmax - clippingmin)\n",
    "\n",
    "                # Get the label and prediction volumes\n",
    "                label_volume = labels[i, 0].cpu().numpy().astype(np.uint8)\n",
    "                output_volume = outputs[i].detach().cpu().numpy()\n",
    "                predicted_labels_volume = np.argmax(output_volume, axis=0).astype(np.uint8)\n",
    "\n",
    "                # Select the middle slice index after argmax reduction\n",
    "                slice_idx = predicted_labels_volume.shape[0] // 2\n",
    "                label_slice = label_volume[slice_idx]\n",
    "                predicted_labels_slice = predicted_labels_volume[slice_idx]\n",
    "\n",
    "                # Apply the color map to the label and prediction slices\n",
    "                label_rgb_slice = color_map[label_slice]\n",
    "                prediction_rgb_slice = color_map[predicted_labels_slice]\n",
    "\n",
    "                # Create the plots\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(input_slice_mid, cmap='gray')\n",
    "                ax[0].set_title(\"Input\")\n",
    "                ax[1].imshow(label_rgb_slice)\n",
    "                ax[1].set_title(\"Ground Truth\")\n",
    "                ax[2].imshow(prediction_rgb_slice)\n",
    "                ax[2].set_title(\"Prediction\")\n",
    "                fig.suptitle(f'VALIDATION-{num}', fontsize=16)\n",
    "                img_path = f\"./PNG/VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\"\n",
    "                print(f\"VALIDATION-{num}_Epoch-{epoch}_iteration-{iteration}_batch-{i}.png\")\n",
    "                # Save the image\n",
    "                plt.savefig(img_path)\n",
    "                plt.close()\n",
    "\n",
    "                # Write to the markdown file\n",
    "                md_file.write(f\"![Epoch-{epoch} Iteration-{iteration} Batch-{i}]({img_path})\\n\\n\")\n",
    "\n",
    "    print(f\"Markdown file updated at {md_file_path}\")\n",
    "\n",
    "\n",
    "# Loss Plotting Function\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "    plt.savefig(\"./PNG/lossfunction.png\")\n",
    "\n",
    "# Main training loop\n",
    "num_epochs = 1000 # Example value\n",
    "display_interval = 1 # Example value\n",
    "\n",
    "\n",
    "def train_step(batch_data, model, loss_function, optimizer, device):\n",
    "    # print(\"Reading in the images\")\n",
    "    print(f\"Processing filenames: {batch_data['filename']}\")\n",
    "    images, labels = batch_data['image'], batch_data['label']\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Passing Through the Network\")\n",
    "    outputs = model(images)\n",
    "\n",
    "    print(f\"Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "    print(\"Label tensor values (sample):\", labels[0, :, 0, 0, 0])\n",
    "    if torch.any(labels == 3):\n",
    "        print(f\"Filename with label 3: {batch_data['filename']}\")\n",
    "\n",
    "    loss = loss_function(outputs, labels)\n",
    "    print(\"Loss Backward\")\n",
    "    loss.backward()\n",
    "    print(\"Stepping Optimizer\")\n",
    "    optimizer.step()\n",
    "    return loss.item(), outputs\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "print(\"Starting the training loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    \n",
    "\n",
    "    # Training Phase\n",
    "    net.train()\n",
    "    num_train = 0\n",
    "    print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")\n",
    "    print(\"\\nReading in the first batch - T ..\")\n",
    "    for iteration, batch_data in enumerate(train_loader):\n",
    "        print(f\"Training Iteration: {iteration}\")\n",
    "        loss, output = train_step(batch_data, net, criterion, optimizer, device)\n",
    "        epoch_train_loss += loss\n",
    "        if iteration % display_interval == 0:\n",
    "            visualize_and_save_train(batch_data['image'], output, batch_data['label'], iteration, epoch, num_train) \n",
    "        print(\"\\nReading in the next batch - T [if any] ..\")\n",
    "        num_train = num_train + 1\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    print(\"Running the validation loop ..\")\n",
    "    \n",
    "    # Validation Phase\n",
    "    net.eval()\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        print(\"Reading in the first batch - V ..\")\n",
    "        for batch_data in val_loader:\n",
    "            print(f\"Validation Iteration: {num}\")\n",
    "            print(f\"Processing filenames: {batch_data['filename']}\")\n",
    "            images, labels = batch_data['image'], batch_data['label']\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            print(f\"Validation - Output shape: {outputs.shape}, Label shape: {labels.shape}\")\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "            if iteration % display_interval == 0:\n",
    "                visualize_and_save_valid(batch_data['image'], outputs, batch_data['label'], iteration, epoch, num) \n",
    "            print(\"Reading in the next batch - V [if any] ..\")\n",
    "            num = num + 1\n",
    "        print()    \n",
    "    \n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "        print(f\"Epoch: {epoch}, Current Learning Rate: {current_lr}\")\n",
    "    # Plot Losses\n",
    "    print(\"Plotting losses ..\")\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# plt.ioff()  # Turn off interactive mode\n",
    "# plt.show()  # Display final plots\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "\n",
    "print(f\"Elapsed: {(time.time()-starttime)/60:.2f} Minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
