///Day 22////////////////////////////////////////////////////////////////////////////////////////////
11/17
	Notes:
		TO-DO
			Some Mesal files listed as MESAL?? Fix code for this next time.
				DONE (code is fixed and will work whether MESA or MESAL is in the file name)
			Fix the rest of the code to ensure MESA and MESAL case files both work fine from start to finish
				DONE
			Double check on case number study ID dictionary.
				DONE
				Cell can now be used for the dictionary whenever case numbers/study IDs have been updated.
			Keep loading image files and writing to the doc. Aim for all files.
				Got through 32 images. Found out that not all spiromics have a subfolder?
				Next time, need to iron out this error and load the rest of the case images.

///Day 21////////////////////////////////////////////////////////////////////////////////////////////
11/16
	Notes:
		TO-DO
			Try and automate the process where given the case number, it finds the correct study ID, take image, and plots.
				DONE
			Fix find_header_file so that it works with both mesal and spiromics.
				DONE
			Make Doc writing code go into a loop and print out all completed images.
				DONE



///Day 20////////////////////////////////////////////////////////////////////////////////////////////
11/13
	Notes:
		Whatever solution we choose, plan ahead to ensure all steps are possible.
		After getting it into the doc, try to remove hard coding of the case image path.

		This case, when viewed in 3D slicer is upside down. I.E. bottom of lung appears superior to top of lung.

		Changed default distance to 700 voxels. Had to play around a lot to get a good view. Now editing word doc
		code to write into a table.

		Does it matter the dimensions? I increased row height to 100pt. Should I increase font size to 12pt?
		Should I add same case numbers list from Nate's image creation code?

		In actual report, images will be put in order.

		LATER check T10 table as it is more up to date for Study ID -> Case Number Dictionaries.
		Also, fix the flipping and everything with Soheil's ReCentering.

		Later check one of Nate's in Slicer to see if it is flipped or not.

		Direction matrix issue solved. Our picture was correct. 


///Day 20////////////////////////////////////////////////////////////////////////////////////////////
11/12
	Notes:
		Image is not currently flipped, and you are not supposed to read in header data into a np array.
		You can get spacing from header file

		Ignore issues with direction matrix and skewness. Just take snapshot, save, attach current image to document.

///Day 20////////////////////////////////////////////////////////////////////////////////////////////
11/9
	Notes:
		Everything above 0 should become 1. Use 3D contour to visualize at level 0.5. Then save figure.
		

///Day 19////////////////////////////////////////////////////////////////////////////////////////////
11/8
	Notes:
		Don't need to do vtk creation anymore.

		(1) Show TLC's in report
			Unzip all, write code for dictionary of case number and patient ID, go to word doc code and export images to proper
			row find lung mask, open header.

			(Read in as NIfTI)
			
		(2) Add disease maps in
		(3) Finalize geometry transformation

///Day 17////////////////////////////////////////////////////////////////////////////////////////////
11/1
	Notes:
		Let's work on adding two-way functionality

		Using threshold filter, increasing/decreasing lower threshold will thin/thicken the image.
		I.e lower threshold of 10 yields a very thick artifact while threshold of 200 yields thinned out
		artifact and gaps along the airway. 100 seems to be a good value.

		Need to decide how we will preserve values of 0, 1, and 2 on arterial tree. Currently with BSpline,
		this is unknown. However, ChatGPT says this can be done using nearest neighbor sampling/interpolation.

///Day 16////////////////////////////////////////////////////////////////////////////////////////////
10/30
	Notes:
		If loss in definition of tree, then lets go from high to low geometry.


///Day 15////////////////////////////////////////////////////////////////////////////////////////////
10/29
	Notes:
		According to ChatGPT, you CANNOT read in an nrrd file using nibabel. Also, we CANNOT read in a nii.gz using nrrd.
		This means we might have to do more research on how each package handles the file metadata to ensure we are 
		being consistent.

		According to ChatGPT, 3D Slicer reports in RAS (Right Anterior Superior)
		nibabel reports in RAS as well
		pynrrd does NOT have a default it reports in (according to ChatGPT), however it appears to be LPS in VsCode
		itk appears to be LPS as well.

///Day 14////////////////////////////////////////////////////////////////////////////////////////////
10/26
	Notes:
		For interpolation use B-spline, airway resampled to arterial tree.
		Take airways and resample it using the arterial tree's origin, spacing, and size.

		Resample itk filter in 3D Slicer 

///Day 13////////////////////////////////////////////////////////////////////////////////////////////
10/24
	Notes:
		Give code using itk
			ex:
				itk.getspacing()
				itk.physicalpointtoindex() - given an image with an origin, orientation, space, and size, we can
											pick an index like 0, 0, 0 and find the physical coordinates.
				itk.resampleimagefilter() - takes an image
				scikit-image (Name of package)
		orientation is all the same, only playing around origin, spacing, and size
		We have many segments with various geometries. We can't show differing geometries in mayavi at once.
		We want to be able to take one of them and bring it to the space of the other. Think about the complexities
		as the two images may just partially overlap. Function should take in two images and return the second image
		in the same geometry as the first.

Airways, original geometry, has not been manipulated:
	Z:/E-Kelly-VidaSegmentals&Sublobes/3- 20Spiromics-10ForKelly-ForERS23/Case42-IA210257_H-17900_20190805_125316_20230524_121115_export/ZUNU_vida-airtree-recentered.nii.gz
Arterial tree, upsampled geometry:
	Z:/D-Images/SPIROMICS-SubStudy/2-Results-CheckedDoneTemp/1-Done/Case-42-Spiromics-67503688/Markups/88-Adam/S-Final-2-label.nrrd

		NOTE: Slicer works in RAS (Right Anterior Superior) while everyone else works in LPS(Left Posterior Superior).

///Day 12////////////////////////////////////////////////////////////////////////////////////////////
	Notes:
		Figured out how to write to word doc. Added my first dummy disease map to the doc. 
		Now to try for the rest of the cases.

		To-do
			Work on screenshot
			Transform disease map from niigz to a nrrd

///Day 11////////////////////////////////////////////////////////////////////////////////////////////
	Notes:
		To-do
			(1) Write dummy lung map to word doc.
			(2) Do real disease map.

		Found reason behind failed commits. Output.nrrd file is too large for gitHub (> 100mb) or at least for 
		our current settings. DO NOT COMMIT ANYMORE. Either change path to a different folder or just do not save.

///Day 9////////////////////////////////////////////////////////////////////////////////////////////
	Notes:
		Combined all three gaussians into a volume successfully. 

	Next:
		(1) Take downsampled and bring to full resolution. DONE
		(2) Three diseases. Each of them with three centers. 
		(3) Play around with real disease map in slicer. 

		Create function that makes testing centers easier?

///Day 8////////////////////////////////////////////////////////////////////////////////////////////
	Notes from Soheil: 
		■ Nick let's see what happens if we hollow out the cubes 
		■ Gaussians + volume rendering ? * 

	Notes:
		3 Centers for gaussians:
			(1) (340, 350, 320)
			(2) (300, 175, 220)
			(3) (165, 235, 300)
		Gaussian distributions complete. 2 things left:
			Need volume rendering rather than contours. No more 0 and 2, we now have intermediate values.
			Put all gaussians into one volume "If you have a gaussian mixture model, how to construct a volume with those gaussians."
			"If you have a gmm how to visualize it?"
	
	Next:
		Achieved volume render of gaussian distribution. Next - work on combining all three gaussians into one volume
		and visualize it. 

///Day 7////////////////////////////////////////////////////////////////////////////////////////////
	Using volume rendering and mayavi. Place 3 dummy gaussian distributions somewhere on the map.
	Start just with 1. Fix issue where distribution is not tight enough. Too large of spread.


///Day 6////////////////////////////////////////////////////////////////////////////////////////////
Notes:
	Spacing fix had no luck. Still slightly zoomed in.


Next:
	After setting color and opacity, save image. Make camera identical to Nate's. 
	Create dummy 3D disease map for self.
		Create volume same size as image. Values 0, 1, 2, 3, 4
		Multiply by lung mask to only keep values in lung
	Get lung WITH airways at TLC instead of FRC (smaller).
	Airway color should correspond to dysanapsis (how small or large the airway is between 0 and 1). E.g. high is red, intermediate is orange, low is yellow.
	Put into word report.

	Gaussian Mixture Model
		Imagine 0 or 2 as possible values. 2 is disease distributed somewhere. You can ask Chat GPT to model this with two gaussians at two centers.
		Input is the field of 0s and 2s. Outputs two centers and two sigmas or two sigma covariance matrices.

///Day 5////////////////////////////////////////////////////////////////////////////////////////////
Notes:
	Changed lungs object from a volume to a 3D contour which fixed issue with not being able to set the opacity
	Ran into an issue with image. Center of mass and distance seems to be derived correctly, but image is still
	not consistent with Nate's. Checking to see if this is possibly due to a difference in 3D dimensions.


Next:  
	After setting color and opacity, save image. Make camera identical to Nate's. 
	Create dummy 3D disease map for self.
	Lung map has values 0, 1, 2, 3, and 4.
	Get lung WITH airways at TLC instead of FRC (smaller).
	Airway color should correspond to dysanapsis (how small or large the airway is between 0 and 1). E.g. high is red, intermediate is orange, low is yellow.
	Put into word report.
	Fix issue with possible difference in voxels



///Day 4////////////////////////////////////////////////////////////////////////////////////////////
New goal - (1) Go into one of the cases
	(2) Find the lung mask for FRC
	(3) Use standard camera to show it.
	(4) Final step is to use TLC (Will have to find)
	(5) Later, we have the maps of the disease of the lung and we want to add to this visualization. !Create 3D lungs at TLC with disease map!

	Substeps
		(1) Load in lung at FRC
		(2) Visualize using mayavi
		(3) Convert values to either 0 or 1
		(4) Find center of mass of the lungs together
		(5) Visualize using standard camera pointing at center of mass from 600mm posterior. (Find code from Nate's)
	
	Start w border cases.
Notes: 
	If values are not 1 for object of interest, make them 1 when visualizing for contour to display in mayavi code.
	For standard camera...
		Need two vessels (A and V) find their center of mass collectively. Then go 600mm in posterior direction.
		Also set FOV. Task 1: Display both lungs in the standard direction. (Problem: if it was just the vessels, we could have only added a couple more lines of code.
		However, since we are using the lungs, we must convert the file to a vtk model.)

		Normally, we cannot mix and match AV and the lungs due to different geometries because of upsampling of AV. However, Kelly's done folder contains one of the same geometry.
		All AV files are on FRC. Will get access to TLC for this.
Next:
	Figure out FOV issue. Keep distance initialization if possible, but edit FOV so that we can fit each case into frame. Start w border cases.
///Day 3////////////////////////////////////////////////////////////////////////////////////////////
Image Creation Code
	TLC = Total Lung Capacity (Full inflation)			FRC = Functional Residual Capacity (Middle of full inspiration and full expiration)
	*For ImageCreationCode, we are dealing with FRC files.
	
	.label and non-label files are similar. One is a segmentation and one is a label map.
		Segmentation or s-Final ~ Segmentation file that might have any random order or number of segments including M.
		Label map ~ Has taken original image and removes M (miscellaneous). This allows for scalar range to be 0, 1, or 2. Label is more standard while s-Final is nonstandard

	Opening as segment vs volume
		Segment ~
		Volume ~

	For path names, when storing prefixes utilize r"path".

	Shortcut to bring up terminal: Ctrl + '~'
	
	Segmentation vs Model/vtk
		Segmentation is a volume of values 0 and 1 while...
		Model or vtk is a collection of edges and vertices, or a mesh, as a representation.
		*For 3D representation, the vtk must be used.

		However, vtk conversion is not always needed EXCEPT when lungs and airways are involved.
	Decimation
		Use surface toolbox

	Purpose
		Using case 16, we want to write out into a file the lungs with arterial tree.
		Start off with vasculature. Find the angle which looks at the center of mass from 60cm away.
		One row and keep all of the columns.

	Notes during troubleshooting:
		Window levels describe the intensity range we want to map to the output image. It determines min and max pixel
		values. -1204 in Hounsfield units is the lowest intensity and corresponds to air. 650 is the max and corresponds
		with bone.

		
Next: Find issue with matplotlib inline, and continue looking into code. Try separating image loading to a different cell.



///Day 2////////////////////////////////////////////////////////////////////////////////////////////
Note: VsCode Terminal = Powershell NOT command prompt

Ran into issues in activating virtual environment. ALWAYS make sure you are installing packages into venvnick. Resolved using the following lines of code:
	(1) Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
	(2) .\venvnick\Scripts\Activate.ps1

Shortcut to run cell: Ctrl + Enter

Nate's Image Creation code
	In CaseImagesFinalDraft
		(1) Shows middle coronal slice while preserving scale.
		(2) Picks last s-final.nrrd, gets rid of M, then systematically visualizes it in a standard* fashion.     *3D visualization camera is set at an exact distance away from the trees. No need to change camera view 
		(3) Shows the lungs and pulmonary artery tree

		At the beginning, the code has functionality that traverses the entire "Done" images folder and picks the correct vx3's and s-final's.
		One cell is for reading the files, one to find images, and another to write out to the word document.

		Sorts through S-Segmentation (avm) files. There are many intermediates and one final (the last final) that is correct. Go through and compare each intermediate to the final, and create a word report of that. 90% Done
		Still need to create word doc that shows incorrect avm trees along with the correct avm tree. Will only 3 columns. Case, avm#, and avf.

		Had to install all import packages. Used ChatGPT to make sure each package was installed correctly.

		Worked on simplifying code. Instead of traversing entire Done folder, just pick out the specific case files and use them. Left off on brainstorming ideas on how to avoid traversing through whole done folder.

///Day 1////////////////////////////////////////////////////////////////////////////////////////////

We created a new GitHub account and added a new branch
Joined Microsoft Teams
Initiated add request for URES:3394. Still require instructor, advisor, and collegiate approval
Downloaded VsCode
Download Git. Cloned repository
Steps to push code:
	(1) Stage change
	(2) Commit change (add notes abd [NM#])
	(3) Push change to remote repository
Associate username: git config --global user.name "moore25l"
Associate email: git config --global user.email "nicholas-moore@uiowa.edu"
Set branch to /nick
Created ChatGPT account

Get access to files (images)
Added a Network Location: \\lc-rs-store25.hpc.uiowa.edu\teamwork
Map to Network Drive: \\lc-rs-store25.hpc.uiowa.edu\teamwork\public_resources\RA4-Project (Drive Name Z:)

Downloaded 3D Slicer
Viewer
	Person looking towards us (left and right are switched)
Blood circulation:
	(1) Deoxygenated blood delivered to heart through superior and inferior vena cava
	(2) Heart pumps deoxygenated blood to lungs through pulmonary artery (blue) tree
			MAIN PULMONARY ARTERY = Root            
	(3) Blood becomes oxygenated and is transferred back to heart through pulmonary venous (red) tree
			MAIN PULMONARY VEINS = Usually 4. Connects back to heart through several "roots" as opposed to 1 with the main pulmonary artery
	(4) Blood is pumped from heart through the aorta to circulation
		From image we looked at, agent went from arm into vena cava into the heart then out into blue.
Image Volume Proprties
	Load segmentation as volume itself
	Care about image dimensions, spacing, and the Scalar Range (for CT images pertains to Attenuation Coefficient Hounsfield units. Air is ~-1024. Water ~0.)
Volume View
	vX3 take image of lungs, crop and upsampled (~0.7mm --> isotropic 0.38mm)

Created Virtual Environment
	Line: python -m venv venvnick
	Made sure to ignore it in .gitignore